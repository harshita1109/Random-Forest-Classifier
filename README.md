# ğŸ· Wine Classifier using Random Forest ğŸŒ¿

## ğŸ” Project Overview
This project builds a **Machine Learning model** that classifies wine samples as **ğŸ‡ Legit** or **ğŸš« Fraudulent** based on their **chemical properties**. Using the **ğŸŒ² Random Forest Classifier**, the model learns patterns from various physicochemical parameters to ensure **wine authenticity** and **quality verification**.

---

## ğŸ§  Objective
Develop a reliable classification system to detect fraudulent wine samples by analyzing quantitative features like acidity, density, alcohol content, and more.

---

## ğŸ“‚ Dataset
The dataset includes several chemical composition features such as:
- ğŸ§ª Fixed acidity  
- ğŸ’¨ Volatile acidity  
- ğŸ‹ Citric acid  
- ğŸ¬ Residual sugar  
- ğŸ§‚ Chlorides  
- ğŸ’§ Free sulfur dioxide  
- ğŸŒ«ï¸ Total sulfur dioxide  
- âš–ï¸ Density  
- ğŸ§« pH  
- ğŸ’¥ Sulphates  
- ğŸ¶ Alcohol  
- ğŸ·ï¸ Quality Label (Legit/Fraud)

ğŸ“Š **Source:** Open-source dataset (Kaggle / UCI ML Repository)

---

## âš™ï¸ Workflow

1. **ğŸ§¹ Data Preprocessing**
   - Handling missing values and outliers  
   - Encoding categorical variables  
   - Scaling numeric features  

2. **ğŸ“Š Exploratory Data Analysis (EDA)**
   - Feature distribution visualization  
   - Correlation heatmap for feature importance  

3. **ğŸ¤– Model Building**
   - Algorithm: ğŸŒ² Random Forest Classifier  
   - Train-test split for model validation  
   - Hyperparameter tuning using GridSearchCV  

4. **ğŸ“ˆ Model Evaluation**
   - Metrics: Accuracy âœ… | Precision ğŸ¯ | Recall ğŸ” | F1-score ğŸ…  
   - Confusion Matrix visualization  

5. **ğŸ§¾ Prediction on Unseen Data**
   - Model (`wine_classifier_model.pkl`) predicts authenticity on new samples  

---

## ğŸ§© Results
âœ… High accuracy on test data  
ğŸ· Successfully distinguishes **legit** vs **fraudulent** wines  
ğŸŒ¿ Random Forest outperformed baseline models (Logistic Regression, Decision Tree)

---

## ğŸ’¡ Key Insights
- ğŸ¶ Alcohol and âš–ï¸ Density strongly correlate with wine authenticity  
- ğŸ§  Ensemble models improve generalization  
- ğŸ“Š Balanced preprocessing enhances model reliability  

---

## ğŸ› ï¸ Technologies Used
| Tool | Purpose |
|------|----------|
| ğŸ Python | Core programming language |
| âš™ï¸ Scikit-learn | ML model building |
| ğŸ“Š Pandas, NumPy | Data processing |
| ğŸ“‰ Matplotlib, Seaborn | Data visualization |
| ğŸ’» Jupyter / Google Colab | Interactive development |

---

## ğŸ“¦ Files in Repository
| File | Description |
|------|--------------|
| `Wine_Classifier(RF).ipynb` | Model training notebook |
| `wine_data.csv` | Dataset used for training |
| `wine_classifier_model.pkl` | Saved trained model |
| `README.txt` | Documentation file |

---

## ğŸš€ How to Run
1. Clone the repository  
   ```bash
   git clone https://github.com/yourusername/Wine-Classifier-RF.git
   ```
2. Navigate to the project folder  
   ```bash
   cd Wine-Classifier-RF
   ```
3. Install dependencies  
   ```bash
   pip install -r requirements.txt
   ```
4. Launch the notebook  
   ```bash
   jupyter notebook Wine_Classifier(RF).ipynb
   ```

---

## ğŸ”® Future Enhancements
- ğŸŒ Deploy using Flask/Django web app  
- ğŸ§© Integrate deep learning models (ANN, CNN)  
- ğŸ’¬ Add explainability (SHAP/LIME) for feature importance visualization  

---

## ğŸ† Author
ğŸ‘¤ **Your Name**  
ğŸ’¬ Passionate about Data Science & ML | Building Intelligent Systems  
ğŸ“§ your.email@example.com  

â­ *If you like this project, consider giving it a star!* ğŸŒŸ


ğŸ† Author

Harshita Sharma
ğŸ’¬ Passionate about Data Science & ML | Building Intelligent Systems
E-mail: harshitash1107@gmail.com
